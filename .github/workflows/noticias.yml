# Nombre del flujo de trabajo
name: Raspador de Noticias Diario

# Define cuándo se ejecutará
on:
  # Permite ejecutarlo manualmente desde la pestaña Actions de GitHub para probar
  workflow_dispatch:
  
  # Ejecución programada (cron job)
  # Este ejemplo se ejecuta todos los días a las 08:00 UTC (10:00 en España en verano)
  # Puedes personalizar la hora en https://crontab.guru/
  schedule:
    - cron: '0 8 * * *'

jobs:
  scrape-and-notify:
    # Se ejecutará en una máquina virtual con Ubuntu
    runs-on: ubuntu-latest

    steps:
      # 1. Descarga el código de tu repositorio
      - name: Checkout del código
        uses: actions/checkout@v4

      # 2. Configura el entorno de Python 3.10
      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # 3. Instala las librerías del archivo requirements.txt
      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 4. Ejecuta el script principal
      - name: Ejecutar el script de scraping
        env:
          # Aquí se inyecta el "secret" que configurarás en GitHub
          NTFY_TOPIC: ${{ secrets.NTFY_TOPIC }}
        run: python main.py
